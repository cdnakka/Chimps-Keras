{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess audio for vggish model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A few Parameters\n",
    "VGGISH_CHECKPOINT_PATH = \"./vggish/model_parameters/vggish_weights.ckpt\"\n",
    "VGGISH_PCA_PARAMS_PATH = \"./vggish/model_parameters/vggish_pca_params.npz\"\n",
    "\n",
    "DATASET_16BIT_PATH = \"D:/Thesis/UrbanSound8K-16bit/audio-classified\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: Augment the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing your install of VGGish\n",
      "\n",
      "Log Mel Spectrogram example:  [[-4.47297436 -4.29457354 -4.14940631 ... -3.9747003  -3.94774997\n",
      "  -3.78687669]\n",
      " [-4.48589533 -4.28825497 -4.139964   ... -3.98368686 -3.94976505\n",
      "  -3.7951698 ]\n",
      " [-4.46158065 -4.29329706 -4.14905953 ... -3.96442484 -3.94895483\n",
      "  -3.78619839]\n",
      " ...\n",
      " [-4.46152626 -4.29365061 -4.14848608 ... -3.96638113 -3.95057575\n",
      "  -3.78538167]\n",
      " [-4.46152595 -4.2936572  -4.14848104 ... -3.96640507 -3.95059567\n",
      "  -3.78537143]\n",
      " [-4.46152565 -4.29366386 -4.14847603 ... -3.96642906 -3.95061564\n",
      "  -3.78536116]]\n",
      "VGGish embedding:  [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16137299 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.8069577\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.3679273  0.035824   0.         0.         0.\n",
      " 0.         0.38027024 0.1375595  0.9174706  0.80656356 0.\n",
      " 0.         0.         0.         0.04036269 0.70762444 0.\n",
      " 0.497839   0.24081801 0.21565409 0.8849231  1.1956804  0.6706198\n",
      " 0.2077946  0.0163987  0.17471868 0.         0.         0.25100818\n",
      " 0.         0.         0.14607918 0.         0.39887056 0.30542123\n",
      " 0.1289675  0.         0.         0.         0.         0.\n",
      " 0.53851354 0.         0.         0.04941103 0.42527404 0.18537295\n",
      " 0.         0.         0.1475353  0.         0.         0.6993388\n",
      " 0.4554118  0.05174839 0.         0.01992527 0.         0.\n",
      " 0.51815784 0.565576   0.6587974  0.         0.         0.4105633\n",
      " 0.         0.         0.         0.25765198 0.23232117 0.24026436\n",
      " 0.         0.         0.         0.         0.         0.2652375\n",
      " 0.         0.48460808 0.         0.         0.19325781 0.\n",
      " 0.20123357 0.         0.03368612 0.         0.         0.\n",
      " 0.         0.17836355 0.02474901 0.0688998  0.         0.\n",
      " 0.         0.08246329 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Postprocessed VGGish embedding:  [169  10 154 127 191  66 124  69 157 232 142  21 128 131  43   3  33 111\n",
      " 198 153  76 255 194  60  71 179 146 131 167  60  79  76 192  84 102 160\n",
      "  23  91 173  13 149 186 115 202 252 163  84 145 107 255   5 198  81   0\n",
      " 203 110  35 104 101 131 255   0   0 158 136  74 115 152  77 154  54 151\n",
      "  82 243  57 116 165 153  85 181 152   0 255 122  29 255  46 105 110  43\n",
      "   0  90  58  13 255 108  96 255  84 121 255  75 176 111 176  64  83 231\n",
      " 255  82 255  94  81 144  99 173 255   0   0 158  31 230 112 255   0 255\n",
      "  20 255]\n",
      "\n",
      "Looks Good To Me!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract Features from Vggish Model\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"./vggish\")\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_keras\n",
    "\n",
    "print('\\nTesting your install of VGGish\\n')\n",
    "\n",
    "# Paths to downloaded VGGish files.\n",
    "checkpoint_path = VGGISH_CHECKPOINT_PATH\n",
    "pca_params_path = VGGISH_PCA_PARAMS_PATH\n",
    "\n",
    "# Relative tolerance of errors in mean and standard deviation of embeddings.\n",
    "rel_error = 0.1  # Up to 10%\n",
    "\n",
    "# Generate a 1 kHz sine wave at 44.1 kHz (we use a high sampling rate\n",
    "# to test resampling to 16 kHz during feature extraction).\n",
    "num_secs = 3\n",
    "freq = 1000\n",
    "sr = 44100\n",
    "t = np.linspace(0, num_secs, int(num_secs * sr))\n",
    "x = np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "# Produce a batch of log mel spectrogram examples.\n",
    "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
    "print('Log Mel Spectrogram example: ', input_batch[0])\n",
    "np.testing.assert_equal(\n",
    "    input_batch.shape,\n",
    "    [num_secs, vggish_params.NUM_FRAMES, vggish_params.NUM_BANDS])\n",
    "\n",
    "# Define VGGish, load the checkpoint, and run the batch through the model to\n",
    "# produce embeddings.\n",
    "model = vggish_keras.get_vggish_keras()\n",
    "model.load_weights(checkpoint_path)\n",
    "embedding_batch = model.predict(input_batch[:,:,:,None])\n",
    "print('VGGish embedding: ', embedding_batch[0])\n",
    "expected_embedding_mean = 0.131\n",
    "expected_embedding_std = 0.238\n",
    "np.testing.assert_allclose(\n",
    "  [np.mean(embedding_batch), np.std(embedding_batch)],\n",
    "  [expected_embedding_mean, expected_embedding_std],\n",
    "  rtol=rel_error)\n",
    "\n",
    "# Postprocess the results to produce whitened quantized embeddings.\n",
    "pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
    "postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "print('Postprocessed VGGish embedding: ', postprocessed_batch[0])\n",
    "expected_postprocessed_mean = 123.0\n",
    "expected_postprocessed_std = 75.0\n",
    "np.testing.assert_allclose(\n",
    "    [np.mean(postprocessed_batch), np.std(postprocessed_batch)],\n",
    "    [expected_postprocessed_mean, expected_postprocessed_std],\n",
    "    rtol=rel_error)\n",
    "\n",
    "print('\\nLooks Good To Me!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like we are going to use the PCA whitened embedding version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed data into the model\n",
    "def getListOfFiles(dirpath):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirpath)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirpath, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)        \n",
    "    \n",
    "    return allFiles\n",
    "\n",
    "def urban_labels(Y, fpaths):\n",
    "    \"\"\"urban sound dataset labels.\"\"\"\n",
    "    urban_label = lambda path: int(os.path.split(path)[-1].split('-')[1])\n",
    "    for p in fpaths:\n",
    "        Y = np.append(Y, [urban_label(p)])\n",
    "    return Y\n",
    "\n",
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    X,sr = librosa.load(file_paths)\n",
    "    raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "# y, sr = librosa.load(path_name)\n",
    "\n",
    "# for i in range(len(sound_file_paths)):\n",
    "#     filepath, sound_name = path_class(sound_file_paths[i])\n",
    "#     raw_sounds = load_sound_files(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of entries in our Dataset:  9712\n",
      "Labels :  (9712,)\n",
      "Filepath :  D:/Thesis/UrbanSound8K-16bit/audio-classified\\air_conditioner\\100852-0-0-13.wav\n",
      "Label :  0.0\n",
      "raw sound:  [ 0.04521289  0.02396493 -0.01914914 ... -0.0242601  -0.01266464\n",
      " -0.02522417]\n",
      "raw sound:  88200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepaths = getListOfFiles(DATASET_16BIT_PATH)\n",
    "print(\"No of entries in our Dataset: \", len(filepaths))\n",
    "\n",
    "Y = np.ndarray(0)\n",
    "labels = urban_labels(Y, filepaths)\n",
    "print(\"Labels : \",labels.shape)\n",
    "\n",
    "raw = []\n",
    "for i in range(10):\n",
    "    #len(filepaths) when ready\n",
    "    raw.append(load_sound_files(filepaths[i]))\n",
    "\n",
    "i = 5\n",
    "print(\"Filepath : \", filepaths[i])\n",
    "print(\"Label : \", labels[i])\n",
    "print(\"raw sound: \", raw[i][0])\n",
    "print(\"raw sound: \", len(raw[i][0]))\n",
    "#Librosa resamples to 22Khz by default at load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a network based on the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
